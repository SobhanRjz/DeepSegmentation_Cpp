#!/usr/bin/env python3
"""
YOLO Segmentation Detection Script - Professional Implementation
This script provides high-performance YOLO segmentation detection with comprehensive 
functionality for football player segmentation.

Author: Generated by Deep C++ Project
Date: 2025
Python Version: 3.10+
"""

from __future__ import annotations

import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union
import warnings

# Third-party imports
import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
import torch

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Suppress unnecessary warnings
warnings.filterwarnings('ignore', category=UserWarning)

# Add YoloPy directory to path for config imports
YOLO_PY_PATH = Path(__file__).parent
sys.path.append(str(YOLO_PY_PATH))

# Configuration loading with fallback
try:
    from config_reader import get_config
    config = get_config(YOLO_PY_PATH / 'config.json')
    CONF_THRESHOLD = config.confidence_threshold
    SCORE_THRESHOLD = config.score_threshold
    NMS_IOU_THRESHOLD = config.nms_threshold
    INPUT_WIDTH = config.input_width
    INPUT_HEIGHT = config.input_height
except ImportError:
    logger.warning("Config reader not available, using fallback values")
    CONF_THRESHOLD = 0.25
    SCORE_THRESHOLD = 0.25
    NMS_IOU_THRESHOLD = 0.45
    INPUT_WIDTH = 1280
    INPUT_HEIGHT = 1280

# Constants
DEFAULT_MODEL_PATH = "YoloModel/yolov8m_SegmentationDetection_dynamic.pt"
DEFAULT_OUTPUT_DIR = "output"
SUPPORTED_IMAGE_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}


class YOLOSegmentationDetector:
    """
    High-performance YOLO Segmentation Detection class.
    
    This class provides comprehensive segmentation detection capabilities optimized
    for football player segmentation with RTX 4070 GPU support.
    
    Features:
        - Model loading and validation
        - Batch processing with optimal memory usage
        - Multiple export formats (ONNX, TensorRT)
        - Professional error handling and logging
        - Memory-efficient processing
        - GPU acceleration support
    """
    
    def __init__(
        self, 
        model_path: Union[str, Path] = DEFAULT_MODEL_PATH,
        output_dir: Union[str, Path] = DEFAULT_OUTPUT_DIR,
        device: Optional[str] = None,
        verbose: bool = True
    ) -> None:
        """
        Initialize the YOLO Segmentation Detector.
        
        Args:
            model_path: Path to the YOLO segmentation model file
            output_dir: Directory to save output files
            device: Device to use ('cuda', 'cpu', or None for auto-detection)
            verbose: Enable verbose logging
        """
        self.model_path = Path(model_path)
        self.output_dir = Path(output_dir)
        self.verbose = verbose
        self.model: Optional[YOLO] = None
        self.input_width = INPUT_WIDTH
        self.input_height = INPUT_HEIGHT
        
        # Device selection
        self.device = self._select_device(device)
        
        # Performance tracking
        self.performance_stats = {
            'total_images': 0,
            'total_time': 0.0,
            'avg_fps': 0.0,
            'memory_usage': 0.0
        }
        
        # Initialize detector
        self._setup_directories()
        self._load_model()
    
    def _select_device(self, device: Optional[str]) -> str:
        """Select optimal device for inference."""
        if device is not None:
            return device
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            if gpu_count > 0:
                gpu_name = torch.cuda.get_device_name(0)
                logger.info(f"Using GPU: {gpu_name}")
                return 'cuda'
        
        logger.info("Using CPU for inference")
        return 'cpu'
    
    def _setup_directories(self) -> None:
        """Create necessary directories with proper error handling."""
        try:
            self.output_dir.mkdir(parents=True, exist_ok=True)
            if self.verbose:
                logger.info(f"Output directory ready: {self.output_dir}")
        except PermissionError:
            logger.error(f"Permission denied creating directory: {self.output_dir}")
            raise
        except Exception as e:
            logger.error(f"Failed to create output directory: {e}")
            raise
    
    def _load_model(self) -> None:
        """Load YOLO model with comprehensive error handling."""
        model_search_paths = [
            self.model_path,
            Path("YoloModel") / self.model_path.name,
            Path("../YoloModel") / self.model_path.name,
            Path("YoloModel/yolov8m_SegmentationDetection_dynamic.pt"),
            Path("YoloModel/yolov8n_player_seg_20250208.pt")
        ]
        
        for path in model_search_paths:
            if path.exists():
                try:
                    self.model = YOLO(str(path))
                    self.model_path = path
                    
                    # Verify model capabilities
                    if not hasattr(self.model.model, 'names'):
                        raise ValueError("Model does not have class names - invalid model")
                    
                    # Check for segmentation support
                    if hasattr(self.model.model, 'task') and self.model.model.task != 'segment':
                        logger.warning("Model may not support segmentation")
                    
                    if self.verbose:
                        logger.info(f"Successfully loaded model: {path}")
                        logger.info(f"Model classes: {list(self.model.model.names.values())}")
                        logger.info(f"Using device: {self.device}")
                    
                    # Move model to device
                    if self.device == 'cuda' and torch.cuda.is_available():
                        self.model.to(self.device)
                    
                    return
                    
                except Exception as e:
                    logger.error(f"Failed to load model from {path}: {e}")
                    continue
        
        # If no model found, raise error
        raise FileNotFoundError(
            f"No valid YOLO model found. Searched paths:\n" +
            "\n".join(f"  - {path}" for path in model_search_paths)
        )
    
    def validate_model(self) -> Dict[str, Any]:
        """Validate model performance and capabilities."""
        if not self.model:
            raise ValueError("Model not loaded")
        
        validation_results = {
            'model_path': str(self.model_path),
            'device': self.device,
            'input_size': (self.input_width, self.input_height),
            'classes': list(self.model.model.names.values()),
            'supports_segmentation': True,
            'memory_usage_mb': 0.0,
            'inference_time_ms': 0.0
        }
        
        # Test inference with dummy image
        try:
            dummy_image = np.random.randint(0, 255, (self.input_height, self.input_width, 3), dtype=np.uint8)
            
            # Measure memory usage
            if torch.cuda.is_available() and self.device == 'cuda':
                torch.cuda.empty_cache()
                memory_before = torch.cuda.memory_allocated() / 1024 / 1024  # MB
            
            # Measure inference time
            start_time = datetime.now()
            _ = self.model.predict(dummy_image, conf=0.25, verbose=False)
            inference_time = (datetime.now() - start_time).total_seconds() * 1000  # ms
            
            if torch.cuda.is_available() and self.device == 'cuda':
                memory_after = torch.cuda.memory_allocated() / 1024 / 1024  # MB
                validation_results['memory_usage_mb'] = memory_after - memory_before
            
            validation_results['inference_time_ms'] = inference_time
            validation_results['status'] = 'valid'
            
            if self.verbose:
                logger.info(f"Model validation successful - Inference: {inference_time:.2f}ms")
            
        except Exception as e:
            validation_results['status'] = 'error'
            validation_results['error'] = str(e)
            logger.error(f"Model validation failed: {e}")
        
        return validation_results
    
    def export_to_onnx(
        self, 
        output_path: Optional[Union[str, Path]] = None,
        dynamic: bool = True,
        simplify: bool = True,
        opset: int = 11
    ) -> Path:
        """
        Export YOLO model to ONNX format with RTX 4070 optimizations.
        
        Args:
            output_path: Path for output ONNX file
            dynamic: Enable dynamic input dimensions
            simplify: Simplify ONNX model for better performance
            opset: ONNX opset version
            
        Returns:
            Path to exported ONNX file
        """
        if not self.model:
            raise ValueError("Model not loaded")
        
        # Generate output path
        if output_path is None:
            model_name = self.model_path.stem
            output_path = self.output_dir / f"{model_name}.onnx"
        else:
            output_path = Path(output_path)
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            logger.info(f"Exporting model to ONNX: {output_path}")
            logger.info(f"Settings - Dynamic: {dynamic}, Simplify: {simplify}, Opset: {opset}")
            
            # Export with optimizations
            success = self.model.export(
                format='onnx',
                dynamic=dynamic,
                imgsz=(self.input_width, self.input_height),
                opset=opset,
                simplify=simplify,
                verbose=self.verbose
            )
            
            # Handle export result
            if success:
                # Find the exported file
                possible_paths = [
                    self.model_path.with_suffix('.onnx'),
                    output_path,
                    Path(success) if isinstance(success, str) else None
                ]
                
                for path in possible_paths:
                    if path and path.exists():
                        # Move to desired location if needed
                        if path != output_path:
                            import shutil
                            shutil.move(str(path), str(output_path))
                        
                        # Log success
                        file_size = output_path.stat().st_size / (1024 * 1024)  # MB
                        logger.info(f"ONNX export successful: {output_path} ({file_size:.2f} MB)")
                        
                        return output_path
                
                raise FileNotFoundError("ONNX export completed but file not found")
            else:
                raise RuntimeError("ONNX export failed")
                
        except Exception as e:
            logger.error(f"ONNX export failed: {e}")
            raise
    
    def detect_and_segment(
        self, 
        image_path: Union[str, Path],
        conf: float = CONF_THRESHOLD,
        iou: float = NMS_IOU_THRESHOLD,
        max_det: int = 300
    ) -> List[Dict[str, Any]]:
        """
        Perform segmentation detection on a single image.
        
        Args:
            image_path: Path to input image
            conf: Confidence threshold
            iou: IoU threshold for NMS
            max_det: Maximum detections per image
            
        Returns:
            List of detection results with masks
        """
        if not self.model:
            raise ValueError("Model not loaded")
        
        image_path = Path(image_path)
        if not image_path.exists():
            raise FileNotFoundError(f"Image not found: {image_path}")
        
        if image_path.suffix.lower() not in SUPPORTED_IMAGE_FORMATS:
            raise ValueError(f"Unsupported image format: {image_path.suffix}")
        
        try:
            # Run inference
            results = self.model.predict(
                str(image_path),
                conf=conf,
                iou=iou,
                max_det=max_det,
                verbose=False,
                device=self.device
            )
            
            # Process results
            detections = []
            for result in results:
                if result.masks is not None:
                    for i, (box, mask, conf_score) in enumerate(
                        zip(result.boxes.xyxy, result.masks.data, result.boxes.conf)
                    ):
                        # Extract detection data
                        x1, y1, x2, y2 = box.tolist()
                        class_id = int(result.boxes.cls[i].item())
                        class_name = self.model.names.get(class_id, f"class_{class_id}")
                        
                        # Process mask
                        mask_array = mask.cpu().numpy()
                        mask_resized = cv2.resize(mask_array, (int(x2-x1), int(y2-y1)))
                        
                        detection = {
                            'bbox': [x1, y1, x2, y2],
                            'confidence': float(conf_score),
                            'class_id': class_id,
                            'class_name': class_name,
                            'mask': mask_resized,
                            'area': float(np.sum(mask_array)),
                            'centroid': self._calculate_centroid(mask_array)
                        }
                        detections.append(detection)
            
            return detections
            
        except Exception as e:
            logger.error(f"Detection failed for {image_path}: {e}")
            raise
    
    def _calculate_centroid(self, mask: np.ndarray) -> Tuple[float, float]:
        """Calculate centroid of a binary mask."""
        moments = cv2.moments(mask.astype(np.uint8))
        if moments['m00'] == 0:
            return (0.0, 0.0)
        
        cx = moments['m10'] / moments['m00']
        cy = moments['m01'] / moments['m00']
        return (float(cx), float(cy))

    def save_results_to_csv(self, results: List, image_name: str, output_filename: str = "det_results.csv") -> str:
        """
        Save segmentation detection results to CSV file.
        
        Args:
            results (List): YOLO segmentation detection results
            image_name (str): Name of the processed image
            output_filename (str): Name of the output CSV file
            
        Returns:
            str: Path to the saved CSV file
        """
        if not results or len(results) == 0:
            logger.warning("No results to save")
            return ""
        
        try:
            result = results[0]
            csv_data = []
            
            # Process detection boxes if available
            if hasattr(result, 'boxes') and result.boxes is not None:
                boxes = result.boxes.data.cpu().numpy()
                
                for i, box in enumerate(boxes):
                    x1, y1, x2, y2, conf, class_id = box
                    
                    # Get class name
                    class_name = self.model.names[int(class_id)] if hasattr(self.model, 'names') else f"class_{int(class_id)}"
                    
                    # Calculate box center and dimensions
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    width = x2 - x1
                    height = y2 - y1
                    area = width * height
                    
                    csv_data.append({
                        'box_area': float(area),
                        'x1': float(x1),
                        'y1': float(y1),
                        'x2': float(x2),
                        'y2': float(y2),
                        'class_id': int(class_id),
                        'class_name': class_name,
                        'confidence': float(conf),
                        'center_x': float(center_x),
                        'center_y': float(center_y),
                        'width': float(width),
                        'height': float(height),
                        'has_mask': hasattr(result, 'masks') and result.masks is not None
                    })
            
            # Process segmentation masks if available
            if hasattr(result, 'masks') and result.masks is not None:
                masks = result.masks.data.cpu().numpy()
                
                for i, mask in enumerate(masks):
                    if i < len(csv_data):
                        # Calculate mask area
                        mask_area = np.sum(mask > 0.5)
                        csv_data[i]['mask_area'] = float(mask_area)
                        csv_data[i]['mask_shape'] = f"{mask.shape[0]}x{mask.shape[1]}"
            
            # Create DataFrame and save to CSV
            if csv_data:
                df = pd.DataFrame(csv_data)
                csv_path = self.output_dir / output_filename
                df.to_csv(csv_path, index=False)
                logger.info(f"Results saved to CSV: {csv_path}")
                logger.info(f"Total detections: {len(csv_data)}")
                return str(csv_path)
            else:
                logger.warning("No detection data to save")
                return ""
                
        except Exception as e:
            logger.error(f"Failed to save results to CSV: {str(e)}")
            raise

    def _generate_smooth_colors(self, num_colors: int) -> List[Tuple[int, int, int]]:
        """
        Generate smooth, distinct colors using HSV color space.
        
        Args:
            num_colors (int): Number of colors to generate
            
        Returns:
            List[Tuple[int, int, int]]: List of BGR color tuples
        """
        colors = []
        for i in range(num_colors):
            # Generate evenly spaced hues
            hue = i / num_colors
            # Use high saturation and value for vibrant colors
            saturation = 0.8 + (i % 3) * 0.1  # Vary saturation slightly
            value = 0.9 + (i % 2) * 0.1       # Vary brightness slightly
            
            # Convert HSV to RGB
            rgb = colorsys.hsv_to_rgb(hue, saturation, value)
            # Convert to BGR for OpenCV (and scale to 0-255)
            bgr = (int(rgb[2] * 255), int(rgb[1] * 255), int(rgb[0] * 255))
            colors.append(bgr)
        
        return colors

    def save_all_masks_combined(self, results: List, original_image_path: str, 
                               output_filename: str = "det_all_masks_combined.jpg",
                               alpha: float = 0.6) -> str:
        """
        Save all segmentation masks combined in one picture with smooth color detection.
        
        Args:
            results (List): YOLO segmentation detection results
            original_image_path (str): Path to the original image
            output_filename (str): Name of the output image file
            alpha (float): Transparency level for mask overlay (0.0 to 1.0)
            
        Returns:
            str: Path to the saved combined masks image
        """
        if not results or len(results) == 0:
            logger.warning("No results to create combined masks")
            return ""
        
        try:
            # Load original image
            image = cv2.imread(original_image_path)
            if image is None:
                raise ValueError(f"Could not load image: {original_image_path}")
            
            result = results[0]
            
            if hasattr(result, 'masks') and result.masks is not None:
                masks = result.masks.data.cpu().numpy()
                num_masks = len(masks)
                
                if num_masks == 0:
                    logger.warning("No masks found in results")
                    return ""
                
                # Generate smooth colors for all masks
                smooth_colors = self._generate_smooth_colors(num_masks)
                
                # Create a combined mask overlay
                overlay = np.zeros_like(image, dtype=np.float32)
                
                for i, mask in enumerate(masks):
                    # Resize mask to match image dimensions
                    mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]))
                    
                    # Apply Gaussian blur for smoother edges
                    mask_smooth = cv2.GaussianBlur(mask_resized, (5, 5), 0)
                    
                    # Create colored mask with smooth color
                    color = smooth_colors[i]
                    
                    # Create mask for this detection
                    mask_indices = mask_smooth > 0.5
                    overlay[mask_indices] = color
                
                # Convert overlay to proper format
                overlay = overlay.astype(np.uint8)
                
                # Blend the overlay with the original image
                result_image = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)
                
                # Add contours for better visualization
                for i, mask in enumerate(masks):
                    mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]))
                    mask_binary = (mask_resized > 0.5).astype(np.uint8)
                    
                    # Find contours
                    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    
                    # Draw contours with the same smooth color
                    color = smooth_colors[i]
                    cv2.drawContours(result_image, contours, -1, color, 2)
                
                # Save combined masks image
                output_path = self.output_dir / output_filename
                cv2.imwrite(str(output_path), result_image)
                logger.info(f"Combined masks image saved to: {output_path}")
                logger.info(f"Combined {num_masks} masks with smooth colors")
                return str(output_path)
            else:
                logger.warning("No masks found in results")
                return ""
                
        except Exception as e:
            logger.error(f"Failed to save combined masks image: {str(e)}")
            raise

    def save_annotated_image(self, results: List, original_image_path: str, 
                           output_filename: str = "det_annotated.jpg") -> str:
        """
        Save annotated image with detection boxes and segmentation masks using smooth colors.
        
        Args:
            results (List): YOLO segmentation detection results
            original_image_path (str): Path to the original image
            output_filename (str): Name of the output image file
            
        Returns:
            str: Path to the saved annotated image
        """
        if not results or len(results) == 0:
            logger.warning("No results to annotate")
            return ""
        
        try:
            # Load original image
            image = cv2.imread(original_image_path)
            if image is None:
                raise ValueError(f"Could not load image: {original_image_path}")
            
            result = results[0]
            
            # Draw segmentation masks if available with smooth colors
            if hasattr(result, 'masks') and result.masks is not None:
                masks = result.masks.data.cpu().numpy()
                num_masks = len(masks)
                
                # Generate smooth colors for all masks
                smooth_colors = self._generate_smooth_colors(num_masks)
                
                for i, mask in enumerate(masks):
                    # Resize mask to match image dimensions
                    mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]))
                    
                    # Apply slight blur for smoother edges
                    mask_smooth = cv2.GaussianBlur(mask_resized, (3, 3), 0)
                    
                    # Create colored mask with smooth color
                    color = smooth_colors[i]
                    colored_mask = np.zeros_like(image)
                    colored_mask[mask_smooth > 0.5] = color
                    
                    # Blend mask with image
                    image = cv2.addWeighted(image, 0.7, colored_mask, 0.3, 0)
            
            # Draw bounding boxes if available
            if hasattr(result, 'boxes') and result.boxes is not None:
                boxes = result.boxes.data.cpu().numpy()
                
                # Generate smooth colors for boxes (matching masks if available)
                num_boxes = len(boxes)
                if hasattr(result, 'masks') and result.masks is not None:
                    box_colors = self._generate_smooth_colors(num_boxes)
                else:
                    box_colors = self._generate_smooth_colors(num_boxes)
                
                for i, box in enumerate(boxes):
                    x1, y1, x2, y2, conf, class_id = box
                    
                    # Get class name
                    class_name = self.model.names[int(class_id)] if hasattr(self.model, 'names') else f"class_{int(class_id)}"
                    
                    # Use smooth color for bounding box
                    box_color = box_colors[i] if i < len(box_colors) else (0, 255, 0)
                    
                    # Draw bounding box
                    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), box_color, 2)
                    
                    # Draw label with matching color background
                    label = f"{class_name}: {conf:.2f}"
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    cv2.rectangle(image, (int(x1), int(y1) - label_size[1] - 10), 
                                (int(x1) + label_size[0], int(y1)), box_color, -1)
                    cv2.putText(image, label, (int(x1), int(y1) - 5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            
            # Save annotated image
            output_path = self.output_dir / output_filename
            cv2.imwrite(str(output_path), image)
            logger.info(f"Annotated image saved to: {output_path}")
            return str(output_path)
            
        except Exception as e:
            logger.error(f"Failed to save annotated image: {str(e)}")
            raise
    
    def save_mask_images(self, results: List, output_prefix: str = "det_mask") -> List[str]:
        """
        Save individual segmentation masks as separate images.
        
        Args:
            results (List): YOLO segmentation detection results
            output_prefix (str): Prefix for mask image filenames
            
        Returns:
            List[str]: Paths to saved mask images
        """
        if not results or len(results) == 0:
            logger.warning("No results to save masks")
            return []
        
        try:
            result = results[0]
            saved_paths = []
            
            if hasattr(result, 'masks') and result.masks is not None:
                masks = result.masks.data.cpu().numpy()
                
                for i, mask in enumerate(masks):
                    # Convert mask to 8-bit image
                    mask_img = (mask * 255).astype(np.uint8)
                    
                    # Save mask image
                    mask_filename = f"{output_prefix}_{i:03d}.png"
                    mask_path = self.output_dir / mask_filename
                    cv2.imwrite(str(mask_path), mask_img)
                    saved_paths.append(str(mask_path))
                
                logger.info(f"Saved {len(saved_paths)} mask images")
            else:
                logger.warning("No masks found in results")
            
            return saved_paths
            
        except Exception as e:
            logger.error(f"Failed to save mask images: {str(e)}")
            raise
    
    def save_masks_on_original(self, results: List, original_image_path: str, 
                              output_filename: str = "masked_image.jpg",
                              alpha: float = 0.4) -> str:
        """
        Save the original image with all segmentation masks overlaid using smooth colors.
        This creates only one output file - the original image with colored masks.
        
        Args:
            results (List): YOLO segmentation detection results
            original_image_path (str): Path to the original image
            output_filename (str): Name of the output image file
            alpha (float): Transparency level for mask overlay (0.0 to 1.0)
            
        Returns:
            str: Path to the saved masked image
        """
        if not results or len(results) == 0:
            logger.warning("No results to overlay masks")
            return ""
        
        try:
            # Load original image
            image = cv2.imread(original_image_path)
            if image is None:
                raise ValueError(f"Could not load image: {original_image_path}")
            
            result = results[0]
            
            if hasattr(result, 'masks') and result.masks is not None:
                masks = result.masks.data.cpu().numpy()
                num_masks = len(masks)
                
                if num_masks == 0:
                    logger.warning("No masks found in results")
                    # Save original image as is
                    output_path = self.output_dir / output_filename
                    cv2.imwrite(str(output_path), image)
                    return str(output_path)
                
                # Generate smooth colors for all masks
                smooth_colors = self._generate_smooth_colors(num_masks)
                
                # Create overlay for all masks
                overlay = np.zeros_like(image, dtype=np.float32)
                
                for i, mask in enumerate(masks):
                    # Resize mask to match image dimensions
                    mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]))
                    
                    # Apply Gaussian blur for smoother edges
                    mask_smooth = cv2.GaussianBlur(mask_resized, (5, 5), 0)
                    
                    # Create colored mask with smooth color
                    color = smooth_colors[i]
                    
                    # Apply color to mask areas
                    mask_indices = mask_smooth > 0.5
                    overlay[mask_indices] = color
                
                # Convert overlay to proper format
                overlay = overlay.astype(np.uint8)
                
                # Blend the overlay with the original image
                result_image = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)
                
                # Add subtle contours for better definition (optional)
                for i, mask in enumerate(masks):
                    mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]))
                    mask_binary = (mask_resized > 0.5).astype(np.uint8)
                    
                    # Find contours
                    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    
                    # Draw thin contours with the same smooth color
                    color = smooth_colors[i]
                    cv2.drawContours(result_image, contours, -1, color, 1)
                
                # Save the final masked image
                output_path = self.output_dir / output_filename
                cv2.imwrite(str(output_path), result_image)
                logger.info(f"Masked image saved to: {output_path}")
                logger.info(f"Applied {num_masks} masks with smooth colors to original image")
                return str(output_path)
            else:
                logger.warning("No masks found in results - saving original image")
                # Save original image as is
                output_path = self.output_dir / output_filename
                cv2.imwrite(str(output_path), image)
                return str(output_path)
                
        except Exception as e:
            logger.error(f"Failed to save masked image: {str(e)}")
            raise

    def process_image_simple(self, image_path: str, conf: float = CONF_THRESHOLD) -> Dict[str, Any]:
        """
        Process an image with segmentation detection and save only one output file:
        the original image with masks overlaid.
        
        Args:
            image_path (str): Path to the image file
            conf (float): Confidence threshold for detections
            
        Returns:
            Dict[str, Any]: Dictionary containing path to saved file and detection info
        """
        logger.info(f"Processing image: {image_path}")
        
        # Get image name for output files
        image_name = os.path.basename(image_path)
        base_name = os.path.splitext(image_name)[0]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Run detection
        results = self.detect_and_segment(image_path, conf)
        
        output_info = {
            'image_path': image_path,
            'image_name': image_name,
            'timestamp': timestamp,
            'detection_count': 0,
            'masked_image_path': '',
            'csv_path': ''
        }
        
        if results and len(results) > 0:
            result = results[0]
            
            # Count detections
            if hasattr(result, 'masks') and result.masks is not None:
                output_info['detection_count'] = len(result.masks)
            elif hasattr(result, 'boxes') and result.boxes is not None:
                output_info['detection_count'] = len(result.boxes)
            
            # Save CSV results
            csv_filename = f"{base_name}_SegmentationDetection_py.csv"
            output_info['csv_path'] = self.save_results_to_csv(results, image_name, csv_filename)
            
            # Save original image with masks overlaid
            masked_filename = f"{base_name}_masked_{timestamp}.jpg"
            output_info['masked_image_path'] = self.save_masks_on_original(results, image_path, masked_filename)
        else:
            # No detections found - save original image and empty CSV
            masked_filename = f"{base_name}_no_detections_{timestamp}.jpg"
            image = cv2.imread(image_path)
            if image is not None:
                output_path = self.output_dir / masked_filename
                cv2.imwrite(str(output_path), image)
                output_info['masked_image_path'] = str(output_path)
            
            # Create empty CSV for no detections
            csv_filename = f"{base_name}_no_detections_{timestamp}.csv"
            csv_path = self.output_dir / csv_filename
            empty_df = pd.DataFrame(columns=[
                'image_name', 'detection_id', 'class_id', 'class_name', 'confidence',
                'x1', 'y1', 'x2', 'y2', 'center_x', 'center_y', 'width', 'height',
                'box_area', 'has_mask', 'mask_area', 'mask_shape'
            ])
            empty_df.to_csv(str(csv_path), index=False)
            output_info['csv_path'] = str(csv_path)
        
        return output_info

    def process_batch_images_native(self, image_paths: List[str], conf: float = CONF_THRESHOLD, batch_size: int = 16) -> Dict[str, Any]:
        """
        Process multiple images using YOLO's native batch processing for maximum efficiency.
        
        Args:
            image_paths (List[str]): List of image file paths
            conf (float): Confidence threshold for detections
            batch_size (int): Number of images to process in each batch
            
        Returns:
            Dict[str, Any]: Dictionary containing batch processing results and metrics
        """
        logger.info(f"Starting YOLO native batch processing of {len(image_paths)} images")
        logger.info(f"Batch size: {batch_size}, Confidence: {conf}")
        
        batch_results = {
            'total_images': len(image_paths),
            'processed_images': 0,
            'total_detections': 0,
            'individual_results': [],
            'timing_metrics': {
                'total_time': 0.0,
                'inference_time': 0.0,
                'postprocess_time': 0.0,
                'total_fps': 0.0,
                'batch_fps': 0.0,
                'batch_times': [],
                'batch_sizes': []
            },
            'failed_images': []
        }
        
        import time
        total_start_time = time.time()
        
        # Process images in batches using YOLO's native batch processing
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i + batch_size]
            current_batch_size = len(batch_paths)
            
            logger.info(f"\n{'='*70}")
            logger.info(f"üöÄ Processing batch {i//batch_size + 1}: {current_batch_size} images")
            logger.info(f"Images {i+1} to {i+current_batch_size} of {len(image_paths)}")
            logger.info(f"{'='*70}")
            
            try:
                # Time the batch inference
                batch_start_time = time.time()
                
                # YOLO's native batch processing - pass multiple images at once
                batch_inference_start = time.time()
                results = self.model(
                    batch_paths,  # Pass list of image paths for batch processing
                    conf=conf,
                    iou=NMS_IOU_THRESHOLD,
                    imgsz=(1280, 1280),
                    save=False,
                    verbose=False
                )
                batch_inference_end = time.time()
                
                inference_time = batch_inference_end - batch_inference_start
                
                # Process results for each image in the batch
                postprocess_start = time.time()
                for j, (image_path, result) in enumerate(zip(batch_paths, results)):
                    try:
                        image_name = os.path.basename(image_path)
                        base_name = os.path.splitext(image_name)[0]
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        
                        detection_count = 0
                        if hasattr(result, 'masks') and result.masks is not None:
                            detection_count = len(result.masks)
                        elif hasattr(result, 'boxes') and result.boxes is not None:
                            detection_count = len(result.boxes)
                        
                        # Save CSV results
                        csv_filename = f"{base_name}_batch_{i+j+1}_SegmentationDetection_py.csv"
                        csv_path = self.save_results_to_csv([result], image_name, csv_filename)
                        
                        # Save masked image
                        masked_filename = f"{base_name}_batch_{i+j+1}_masked_{timestamp}.jpg"
                        masked_path = self.save_masks_on_original([result], image_path, masked_filename)
                        
                        # Store individual result
                        individual_result = {
                            'image_path': image_path,
                            'image_name': image_name,
                            'timestamp': timestamp,
                            'detection_count': detection_count,
                            'masked_image_path': masked_path,
                            'csv_path': csv_path,
                            'batch_number': i//batch_size + 1,
                            'image_in_batch': j + 1
                        }
                        
                        batch_results['individual_results'].append(individual_result)
                        batch_results['processed_images'] += 1
                        batch_results['total_detections'] += detection_count
                        
                        logger.info(f"   ‚úÖ Image {i+j+1}: {detection_count} detections")
                        
                    except Exception as e:
                        logger.error(f"   ‚ùå Failed to process image {i+j+1}: {str(e)}")
                        batch_results['failed_images'].append({
                            'image_path': image_path,
                            'error': str(e),
                            'batch_number': i//batch_size + 1
                        })
                
                postprocess_end = time.time()
                batch_end_time = time.time()
                
                # Calculate batch timing metrics
                total_batch_time = batch_end_time - batch_start_time
                postprocess_time = postprocess_end - postprocess_start
                batch_fps = current_batch_size / total_batch_time
                
                batch_results['timing_metrics']['batch_times'].append(total_batch_time)
                batch_results['timing_metrics']['batch_sizes'].append(current_batch_size)
                
                # Log batch performance
                logger.info(f"\nüìä Batch {i//batch_size + 1} Performance:")
                logger.info(f"   Batch size: {current_batch_size} images")
                logger.info(f"   Inference time: {inference_time:.4f} seconds")
                logger.info(f"   Postprocessing time: {postprocess_time:.4f} seconds")
                logger.info(f"   Total batch time: {total_batch_time:.4f} seconds")
                logger.info(f"   Batch FPS: {batch_fps:.2f} images/second")
                logger.info(f"   Avg per image: {total_batch_time/current_batch_size:.4f} seconds")
                logger.info(f"   Detections in batch: {sum(r['detection_count'] for r in batch_results['individual_results'][-current_batch_size:])}")
                
            except Exception as e:
                logger.error(f"‚ùå Failed to process batch {i//batch_size + 1}: {str(e)}")
                for path in batch_paths:
                    batch_results['failed_images'].append({
                        'image_path': path,
                        'error': str(e),
                        'batch_number': i//batch_size + 1
                    })
        
        total_end_time = time.time()
        total_processing_time = total_end_time - total_start_time
        
        # Calculate final metrics
        if batch_results['processed_images'] > 0:
            batch_results['timing_metrics']['total_time'] = total_processing_time
            batch_results['timing_metrics']['total_fps'] = batch_results['processed_images'] / total_processing_time
            
            # Calculate average batch performance
            if batch_results['timing_metrics']['batch_times']:
                avg_batch_time = sum(batch_results['timing_metrics']['batch_times']) / len(batch_results['timing_metrics']['batch_times'])
                avg_batch_size = sum(batch_results['timing_metrics']['batch_sizes']) / len(batch_results['timing_metrics']['batch_sizes'])
                batch_results['timing_metrics']['batch_fps'] = avg_batch_size / avg_batch_time
        
        # Print comprehensive final summary
        logger.info(f"\n{'='*80}")
        logger.info(f"üèÅ YOLO NATIVE BATCH PROCESSING COMPLETE!")
        logger.info(f"{'='*80}")
        logger.info(f"üìä FINAL BATCH METRICS:")
        logger.info(f"   Total images: {batch_results['total_images']}")
        logger.info(f"   Successfully processed: {batch_results['processed_images']}")
        logger.info(f"   Failed images: {len(batch_results['failed_images'])}")
        logger.info(f"   Total detections: {batch_results['total_detections']}")
        logger.info(f"   Batch size used: {batch_size}")
        logger.info(f"   Number of batches: {len(batch_results['timing_metrics']['batch_times'])}")
        logger.info(f"   Total processing time: {total_processing_time:.4f} seconds")
        logger.info(f"   Overall FPS: {batch_results['timing_metrics']['total_fps']:.2f}")
        logger.info(f"   Average batch FPS: {batch_results['timing_metrics']['batch_fps']:.2f}")
        logger.info(f"   Throughput: {batch_results['processed_images'] * 60.0 / total_processing_time:.1f} images/minute")
        
        if batch_results['timing_metrics']['batch_times']:
            import statistics
            times = batch_results['timing_metrics']['batch_times']
            logger.info(f"\n‚è±Ô∏è  BATCH TIMING STATISTICS:")
            logger.info(f"   Min batch time: {min(times):.4f} seconds")
            logger.info(f"   Max batch time: {max(times):.4f} seconds")
            logger.info(f"   Median batch time: {statistics.median(times):.4f} seconds")
            logger.info(f"   Avg batch time: {statistics.mean(times):.4f} seconds")
            if len(times) > 1:
                logger.info(f"   Std dev batch time: {statistics.stdev(times):.4f} seconds")
        
        logger.info(f"{'='*80}")
        
        return batch_results

    def create_test_image_list(self, base_image_path: str, count: int = 50) -> List[str]:
        """
        Create a list of test images by repeating the base image.
        
        Args:
            base_image_path (str): Path to the base test image
            count (int): Number of test images to create in the list
            
        Returns:
            List[str]: List of image paths for batch processing
        """
        if not os.path.exists(base_image_path):
            raise FileNotFoundError(f"Base test image not found: {base_image_path}")
        
        # Create list by repeating the same image
        image_list = [base_image_path] * count
        
        logger.info(f"Created test image list with {count} copies of: {base_image_path}")
        return image_list


def export_yolo_to_onnx(model_path: str, output_path: Optional[str] = None, 
                       dynamic: bool = True, simplify: bool = False, opset: int = 11) -> str:
    """
    Standalone function to export YOLO model to ONNX format with dynamic input dimensions.
    
    Args:
        model_path (str): Path to the YOLO model file (.pt)
        output_path (Optional[str]): Path for the output ONNX file. If None, uses model name with .onnx extension
        dynamic (bool): Whether to use dynamic input dimensions (batch, height, width)
        simplify (bool): Whether to simplify the ONNX model
        opset (int): ONNX opset version to use
        
    Returns:
        str: Path to the exported ONNX file
        
    Example:
        # Export with dynamic dimensions (recommended)
        onnx_path = export_yolo_to_onnx("model.pt", dynamic=True)
        
        # Export with specific output path
        onnx_path = export_yolo_to_onnx("model.pt", "my_model_dynamic.onnx", dynamic=True)
    """
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found: {model_path}")
    
    # Load the model
    model = YOLO(model_path)
    
    # Generate output path if not provided
    if output_path is None:
        model_name = os.path.splitext(os.path.basename(model_path))[0]
        model_dir = os.path.dirname(model_path)
        output_path = os.path.join(model_dir, f"{model_name}_dynamic.onnx")
    
    # Ensure output directory exists
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    print(f"Starting ONNX export...")
    print(f"Model: {model_path}")
    print(f"Output: {output_path}")
    print(f"Dynamic input: {dynamic}")
    print(f"Simplify: {simplify}")
    print(f"Opset: {opset}")
    
    try:
        # Export model to ONNX with dynamic=False for better C++ compatibility
        print(f"üîÑ Exporting model to ONNX format...")
        print(f"   Model: {model_name}")
        print(f"   Input size: {INPUT_WIDTH}x{INPUT_HEIGHT}")
        print(f"   Dynamic shapes: False (for C++ compatibility)")
        
        success = model.export(
            format="onnx",
            imgsz=(INPUT_HEIGHT, INPUT_WIDTH),
            dynamic=False,  # Set to False for C++ compatibility
            simplify=True,
            opset=12,
            verbose=True
        )
        
        if success:
            print(f"‚úÖ Model exported successfully to: {output_path}")
            
            # Test the exported model to verify it works
            print(f"üîç Testing exported ONNX model...")
            import onnx
            import onnxruntime as ort
            
            # Load and verify the ONNX model
            onnx_model = onnx.load(output_path)
            onnx.checker.check_model(onnx_model)
            print(f"‚úÖ ONNX model structure is valid")
            
            # Test inference with ONNXRuntime
            session = ort.InferenceSession(output_path)
            
            # Get input/output info
            input_info = session.get_inputs()[0]
            output_info = session.get_outputs()
            
            print(f"üìä ONNX Model Information:")
            print(f"   Input name: {input_info.name}")
            print(f"   Input shape: {input_info.shape}")
            print(f"   Input type: {input_info.type}")
            
            for i, output in enumerate(output_info):
                print(f"   Output {i} name: {output.name}")
                print(f"   Output {i} shape: {output.shape}")
                print(f"   Output {i} type: {output.type}")
            
            # Test with dummy input
            import numpy as np
            dummy_input = np.random.randn(1, 3, INPUT_HEIGHT, INPUT_WIDTH).astype(np.float32)
            outputs = session.run(None, {input_info.name: dummy_input})
            
            print(f"üß™ Test inference results:")
            for i, output in enumerate(outputs):
                print(f"   Output {i} shape: {output.shape}")
                print(f"   Output {i} data type: {output.dtype}")
                print(f"   Output {i} value range: [{np.min(output):.6f}, {np.max(output):.6f}]")
                if np.any(np.isnan(output)):
                    print(f"   ‚ö†Ô∏è  Output {i} contains NaN values!")
                else:
                    print(f"   ‚úÖ Output {i} contains valid values")
            
            return output_path
        else:
            print(f"‚ùå Failed to export model")
            return None
            
    except Exception as e:
        print(f"‚ùå Failed to export model to ONNX: {str(e)}")
        raise


def main():
    """Main function to run the segmentation detection with batch processing."""
    # Configuration - use available model
    MODEL_PATH = "../YoloModel/yolov8m_SegmentationDetection_dynamic.pt"
    OUTPUT_DIR = "output"
    
    # Default test image (you can change this)
    DEFAULT_IMAGE = "../Dataset/input_SegmentationDetection/TestImage.png"
    
    print("=== YOLO Segmentation Detection with Batch Processing ===")
    
    # Check if model exists, try alternative paths
    model_paths = [
        MODEL_PATH,
        "YoloModel/yolov8n_player_seg_20250208.pt",
        "../YoloModel/yolov8m_SegmentationDetection_dynamic.pt"
    ]
    
    actual_model_path = None
    for path in model_paths:
        if os.path.exists(path):
            actual_model_path = path
            print(f"‚úÖ Found model: {path}")
            break
    
    if actual_model_path is None:
        print(f"‚ùå No model found in any of these paths:")
        for path in model_paths:
            print(f"   - {path}")
        print("Please provide a valid model path.")
        return 1
    
    # Initialize detector
    try:
        detector = YOLOSegmentationDetector(actual_model_path, OUTPUT_DIR)
        
        # Check if test image exists
        if not os.path.exists(DEFAULT_IMAGE):
            print(f"\n‚ö†Ô∏è  Test image not found: {DEFAULT_IMAGE}")
            # Try alternative paths
            alternative_images = [
                "Dataset/input_SegmentDetection/TestImage.png", 
                "../Dataset/input_SegmentDetection/TestImage.png",
                "TestImage.png"
            ]
            
            test_image_found = False
            for alt_image in alternative_images:
                if os.path.exists(alt_image):
                    DEFAULT_IMAGE = alt_image
                    test_image_found = True
                    print(f"‚úÖ Found alternative test image: {alt_image}")
                    break
            
            if not test_image_found:
                print("‚ùå No test image found. Skipping batch processing demo.")
                return 1
        
        print(f"\nüöÄ Starting YOLO native batch processing with 50 images...")
        print(f"Using test image: {DEFAULT_IMAGE}")
        
        # Create list of 50 test images (same image repeated)
        test_image_list = detector.create_test_image_list(DEFAULT_IMAGE, count=50)
        
        # Configure batch processing parameters
        BATCH_SIZE = 1  # Optimal batch size for most GPUs
        print(f"üîß Batch processing configuration:")
        print(f"   Total images: 50")
        print(f"   Batch size: {BATCH_SIZE}")
        print(f"   Number of batches: {(50 + BATCH_SIZE - 1) // BATCH_SIZE}")
        print(f"   Using YOLO's native batch processing for maximum efficiency")
        
        # Process batch with YOLO's native batch processing
        batch_results = detector.process_batch_images_native(
            image_paths=test_image_list,
            conf=0.25,
            batch_size=BATCH_SIZE
        )
        
        # Save batch summary to CSV
        try:
            import pandas as pd
            
            # Create detailed results DataFrame
            results_data = []
            for i, result in enumerate(batch_results['individual_results']):
                results_data.append({
                    'image_number': i + 1,
                    'image_name': result['image_name'],
                    'batch_number': result['batch_number'],
                    'image_in_batch': result['image_in_batch'],
                    'detections_found': result['detection_count'],
                    'timestamp': result['timestamp'],
                    'masked_image_path': result['masked_image_path'],
                    'csv_path': result['csv_path']
                })
            
            df = pd.DataFrame(results_data)
            summary_csv_path = os.path.join(OUTPUT_DIR, "batch_processing_summary.csv")
            df.to_csv(summary_csv_path, index=False)
            print(f"\nüíæ Batch summary saved to: {summary_csv_path}")
            
            # Create timing statistics CSV
            timing_stats = {
                'metric': [
                    'Total Images',
                    'Successfully Processed',
                    'Failed Images', 
                    'Total Detections',
                    'Batch Size Used',
                    'Number of Batches',
                    'Total Processing Time (s)',
                    'Overall FPS',
                    'Average Batch FPS',
                    'Throughput (images/min)',
                    'Min Batch Time (s)',
                    'Max Batch Time (s)',
                    'Median Batch Time (s)',
                    'Average Batch Time (s)'
                ],
                'value': [
                    batch_results['total_images'],
                    batch_results['processed_images'],
                    len(batch_results['failed_images']),
                    batch_results['total_detections'],
                    BATCH_SIZE,
                    len(batch_results['timing_metrics']['batch_times']),
                    batch_results['timing_metrics']['total_time'],
                    batch_results['timing_metrics']['total_fps'],
                    batch_results['timing_metrics']['batch_fps'],
                    batch_results['processed_images'] * 60.0 / batch_results['timing_metrics']['total_time'],
                    min(batch_results['timing_metrics']['batch_times']) if batch_results['timing_metrics']['batch_times'] else 0,
                    max(batch_results['timing_metrics']['batch_times']) if batch_results['timing_metrics']['batch_times'] else 0,
                    pd.Series(batch_results['timing_metrics']['batch_times']).median() if batch_results['timing_metrics']['batch_times'] else 0,
                    pd.Series(batch_results['timing_metrics']['batch_times']).mean() if batch_results['timing_metrics']['batch_times'] else 0
                ]
            }
            
            timing_df = pd.DataFrame(timing_stats)
            timing_csv_path = os.path.join(OUTPUT_DIR, "batch_timing_statistics.csv")
            timing_df.to_csv(timing_csv_path, index=False)
            print(f"üíæ Timing statistics saved to: {timing_csv_path}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not save batch summary to CSV: {str(e)}")
        
        print("\n" + "="*80)
        print("üéâ BATCH PROCESSING DEMO COMPLETE!")
        print("="*80)
        print(f"‚úÖ Successfully processed {batch_results['processed_images']} out of {batch_results['total_images']} images")
        print(f"‚ö° Overall performance: {batch_results['timing_metrics']['total_fps']:.2f} FPS")
        print(f"üîç Total detections found: {batch_results['total_detections']}")
        print(f"‚è±Ô∏è  Total time: {batch_results['timing_metrics']['total_time']:.2f} seconds")
        print(f"üìà Throughput: {batch_results['processed_images'] * 60.0 / batch_results['timing_metrics']['total_time']:.1f} images/minute")
        print("="*80)
            
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        return 1
    
    return 0


if __name__ == "__main__":
    main()